from st_pages import Page, show_pages, add_page_title
import streamlit as st
import pandas as pd
import numpy as np
from datetime import datetime
import os
from PIL import Image
import requests
from flask import Flask, request, jsonify
import re
from langchain_upstage import ChatUpstage
from langchain_core.messages import HumanMessage, SystemMessage
from langchain_community.vectorstores import Chroma

import langchain
langchain.verbose = False
import pysqlite3
import sys
sys.modules['sqlite3'] = sys.modules.pop('pysqlite3')


from OCR import extract_clauses_as_dict
from CLAUSE import extract_legal_terms, legal_explanations, generate_clause_explanation, terms_df, explain_legal_term
from DETECTION import initialize_embeddings, load_vector_store, detection


add_page_title()

show_pages(
    [
        Page("app.py", "Home", "ğŸ "),
        Page("chat.py", "Page 2", ":books:"),

    ]
)



persist_directory = "./chroma_data"
persist_directory_db = "./chroma_db"


api_key = st.secrets['API_KEY']
embeddings = initialize_embeddings(api_key)
vector_store = load_vector_store(persist_directory, embeddings)
db = load_vector_store(persist_directory_db, embeddings)
retriever = db.as_retriever()
	
st.title("ì „ì„¸/ì›”ì„¸ ì‚¬ê¸°ê³„ì•½ ë°©ì§€ë¥¼ ìœ„í•œ ë¶€ë™ì‚°ê³„ì•½ì„œ ê²€í† -ë¶„ì„ ì„œë¹„ìŠ¤ ")
st.write(""" ëª…í’ˆì¸ì¬ x ì—…ìŠ¤í…Œì´ì§€ LLM Innovators Challenge """,unsafe_allow_html=True)
st.write(""" <p> team <b style="color:red">ì²´í¬ë©”ì´íŠ¸</b></p>""",unsafe_allow_html=True)
st.divider()
st.subheader('ê²€í† -ë¶„ì„ì´ í•„ìš”í•œ ê³„ì•½ì„œëŠ”?')
file = st.file_uploader('ê³„ì•½ì„œë¥¼ ì—…ë¡œë“œ í•˜ì„¸ìš”', type=['jpg', 'jpeg', 'png'])

def save_uploaded_file(directory, file):
    if not os.path.exists(directory):
        os.makedirs(directory)
    with open(os.path.join(directory, file.name), 'wb') as f:
        f.write(file.getbuffer())

if file is not None:
    current_time = datetime.now().isoformat().replace(':', '_')
    file.name = current_time + '.jpg'

    save_uploaded_file('tmp', file)

    img = Image.open(file)
    st.image(img)
    
    file_path = os.path.join('tmp', file.name)

    # OCR API í˜¸ì¶œ
    def extract_text_from_document(api_key, filename):
        url = "https://api.upstage.ai/v1/document-ai/ocr"
        headers = {"Authorization": f"Bearer {api_key}"}
        files = {"document": open(filename, "rb")}
        response = requests.post(url, headers=headers, files=files)
        return response.json()

    
    api_key = st.secrets['API_KEY']
    ocr_result = extract_text_from_document(api_key, file_path)

    def extract_ocr_text(ocr_result):
        ocr_text = " ".join(page['text'] for page in ocr_result['pages'])
        return ocr_text

    # OCR ê²°ê³¼ì—ì„œ í…ìŠ¤íŠ¸ ì¶”ì¶œ
    ocr_text = extract_ocr_text(ocr_result)
    
    # ìµœì¢…ì ìœ¼ë¡œ ì¡°í•­ì„ ë¶„ë¦¬í•˜ê³  ê²°ê³¼ë¥¼ ë”•ì…”ë„ˆë¦¬ë¡œ ì €ì¥
    final_classified_text = extract_clauses_as_dict(ocr_text)
    
    # final_classified_textì—ì„œ 'type'ì´ 'ì¡°í•­'ì¸ í•­ëª©ë“¤ì˜ 'content'ë¥¼ ì¶”ì¶œí•˜ì—¬ risky_clause ë¦¬ìŠ¤íŠ¸ì— ì €ì¥
    clauses = []

    for key, clause in final_classified_text.items():
        clauses.append(clause)  # ì¡°í•­ ë‚´ìš©ì„ ë¦¬ìŠ¤íŠ¸ì— ì¶”ê°€



    for i, clause in enumerate(clauses):
        # ìœ„í—˜ ì¡°í•­ ê°ì§€
        sim_clause, judgment, reason, detection_result = detection(clause, vector_store, embeddings)

        # ì¡°í•­ ì¶œë ¥ ìŠ¤íƒ€ì¼ ê²°ì • (ìœ„í—˜ ì¡°í•­ì¸ ê²½ìš° ë¹¨ê°„ìƒ‰ í…Œë‘ë¦¬)
        if detection_result == 1:
            st.markdown(
                f"<div style='padding: 10px; border: 2px solid red; border-radius: 5px; background-color: #ffe6e6;'>{clause}</div>", 
                unsafe_allow_html=True
            )
        else:
            st.markdown(
                f"<div style='padding: 10px; border: 1px solid #ddd; border-radius: 5px; background-color: #f0f0f0;'>{clause}</div>", 
                unsafe_allow_html=True
            )

        # ì¡°í•­ì—ì„œ ë²•ë¥  ìš©ì–´ ì¶”ì¶œ ë° ì„¤ëª… ê°€ì ¸ì˜¤ê¸°
        legal_terms = extract_legal_terms(clause, terms_df)
        term_explanations = legal_explanations(legal_terms, terms_df)

        # ìœ„í—˜ ì¡°í•­ì¸ ê²½ìš° ì¶”ê°€ ì •ë³´ ì¶œë ¥
        if detection_result == 1:
            explanation = generate_clause_explanation(clause, term_explanations, True, sim_clause, judgment)
            st.write("")
            st.write("**ì¡°í•­ í•´ì„¤**")
            st.write(explanation)
            st.write("**âš ï¸ ìœ ì‚¬í•œ ìœ„í—˜ ì¡°í•­ ë°œê²¬**")
            st.write(f"ìœ ì‚¬ ì¡°í•­: {sim_clause}")
            st.write(f"ì „ë¬¸ê°€ ê²¬í•´: {judgment}")
            reason = reason.split('<sep>')
            for r in reason:
                context_docs = retriever.invoke(r)
                r = context_docs[0].metadata['source'] + " " + r
                st.write("**ë²•ì  ê·¼ê±°**")
                st.write(r)
                                                
        else:
            explanation = generate_clause_explanation(clause, term_explanations)
            st.write("")
            st.write("**ì¡°í•­ í•´ì„¤**")
            st.write(explanation)

        st.divider()